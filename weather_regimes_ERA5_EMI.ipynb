{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etude des régimes de temps\n",
    "\n",
    "\n",
    "**Auteur : FERRY Frédéric (ENM/C3M) - Novembre 2021.\n",
    "mailto:frederic.ferry@meteo.fr\n",
    "\n",
    "Les régimes de temps sont des briques élémentaires de la circulation extratropicale de grande échelle spatialement bien définis, récurrents, de durée de vie de l’ordre de quelques jours à quelques semaines. **Le régime de temps est la principale entité physique des fluctuations atmosphériques aux moyennes latitudes** et les changements du temps qu'il fait peuvent se comprendre comme le passage d'un régime à un autre. La variabilité climatique peut, quant à elle, s'interpréter comme la conséquence sur une longue période de transitions privilégiées vers un régime donné. Ainsi, le concept de régime de temps fournit une grille de lecture simplificatrice du climat des latitudes moyennes et de son évolution.\n",
    "\n",
    "**On s'intéressera ici à l'étude des régimes de temps de l'Atlantique Nord (et éventuellement du Pacifique nord) à partir de séries quotidiennes de géopotentiel à 500 hPa et de pression réduite au niveau de la mer**. \n",
    "\n",
    "- Etape 1 : ouverture et traitement des données quotidiennes\n",
    "- Etape 2 : étude des données quotidiennes sur un mois donné\n",
    "- Etape 3 : décomposition des données en temps et en espace (analyse en composantes principales, ACP)\n",
    "- Etape 4 : classification en 4 classes = régimes (méthode k-means)\n",
    "- Etape 5 : obtention des régimes de temps\n",
    "- Etape 6 : temps sensible associé aux régimes de temps (étape à faire uniquement pour les régimes de temps d'hiver sur l'Atlantique nord)\n",
    "- Etape 7 : étude des occurrences saisonnières des régimes de temps\n",
    "- Etape 8 : retour sur une saison particulière\n",
    "\n",
    "**Remarque : la technique d'analyse en composantes principales (ACP) et la méthode de classification de type k-means seront abordés en deuxième année. Ces outils d'analyse de données sont à utiliser ici comme des \"boîtes noires\"**.\n",
    "\n",
    "Concepts Python illustrés :\n",
    "\n",
    "- Exploitation de fichiers de données météorologiques au format netcdf (xarray/netCDF4)\n",
    "- Calcul d'anomalies quotidiennes (méthode groupby de xarray)\n",
    "- Création de séries temporelles (pandas)\n",
    "- Tracé de cartes (matplotlib/cartopy)\n",
    "- Régression linéaire (module LinearRegression de sklearn, https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "- Analyse en composantes principales (package eofs, https://ajdawson.github.io/eofs/latest/)\n",
    "- Représentation des données dans un espace des phases (scatterplot 2D ou 3D)\n",
    "- Tracé de densité de points (module gaussian_kde de scipy)\n",
    "- Classification K-means (module KMeans de sklearn, https://scikit-learn.org/stable/modules/clustering.html)\n",
    "- Réalisation de cartes composites (moyenne par classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24156/1674595893.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnetCDF4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xarray'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import calendar\n",
    "from calendar import isleap\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import IPython.display as IPdisplay, matplotlib.font_manager as fm\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.path as mpath\n",
    "\n",
    "from cartopy import config\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "from eofs.standard import Eof\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dossiers des données, figures, animations et résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dir_data='./data/'\n",
    "dir_res='./result/'\n",
    "dir_figs='./figs/'\n",
    "dir_anim='./anim/'\n",
    "\n",
    "if not os.path.exists(dir_figs):\n",
    "    os.makedirs(dir_figs)\n",
    "if not os.path.exists(dir_anim):\n",
    "    os.makedirs(dir_anim)\n",
    "if not os.path.exists(dir_res):\n",
    "    os.makedirs(dir_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 1 : ouverture et traitement des données quotidiennes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ouverture (via xarray) du fichier des données :\n",
    "\n",
    "era5_z500_natl_daily_1950-2020.nc :\n",
    "Fichier au format netcdf issu des réanalyses quotidiennes ERA5\n",
    "Les données sont des valeurs quotidiennes de hauteur géopotentielle à 500hPa (variable z, unité : mgp) sur l'Atlantique nord et pour la période 1979-2020.\n",
    "\n",
    "era5_msl_natl_daily_1950-2020.nc :\n",
    "Fichier au format netcdf issu des réanalyses quotidiennes ERA5\n",
    "Les données sont des valeurs quotidiennes de pression réduite au niveau de la mer (variable msl, unité : Pa) sur l'Atlantique nord et pour la période 1979-2020."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Choix de la variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var_text=input(\"Z500 ou Pmer : Z500/MSLP? \")\n",
    "\n",
    "if var_text=='Z500':\n",
    "    infile = dir_data+'era5_z500_natl_daily_1950-2020.nc'\n",
    "    varname='z'\n",
    "    var_div=9.81\n",
    "    units='m'\n",
    "\n",
    "if var_text=='MSLP':\n",
    "    infile = dir_data+'era5_msl_natl_daily_1950-2020.nc'\n",
    "    varname='msl'\n",
    "    var_div=100\n",
    "    units='hPa'\n",
    "\n",
    "data0    = xr.open_dataset(infile)\n",
    "print(data0.variables)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Choix de la saison et du domaine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "domain_name=input(\"Domaine Atlantique nord ou Pacifique : natl/npac ? \")\n",
    "season_name=input(\"Saison hiver ou été : winter/summer ? \")\n",
    "\n",
    "if domain_name=='natl':\n",
    "    domain='North Atlantic'\n",
    "    latS=20\n",
    "    latN=80\n",
    "    lonW=-80\n",
    "    lonE=30\n",
    "if domain_name=='npac':\n",
    "    domain='North Pacific'\n",
    "    latS=20\n",
    "    latN=80\n",
    "    lonW=115\n",
    "    lonE=285\n",
    "\n",
    "if season_name=='winter':\n",
    "    season='Winter'\n",
    "    if var_text=='MSLP':\n",
    "        startday  = '1950-12-01T09'\n",
    "        endday  = '2020-03-31T09'\n",
    "    if var_text=='Z500':\n",
    "        startday  = '1950-12-01T18'\n",
    "        endday  = '2020-03-31T18'\n",
    "if season_name=='summer':\n",
    "    season='Summer'\n",
    "    if var_text=='MSLP':\n",
    "        startday  = '1950-06-01T09'\n",
    "        endday  = '2020-09-30T09'\n",
    "    if var_text=='Z500':\n",
    "        startday  = '1950-06-01T18'\n",
    "        endday  = '2020-09-30T18'\n",
    "\n",
    "# Date index from startday to endday\n",
    "dates = pd.date_range(startday, endday, freq='D')\n",
    "print(dates)\n",
    "\n",
    "# Remove 29/02\n",
    "#def is_leap_and_29Feb(s):\n",
    "#    return (s.year % 4 == 0) & ((s.year % 100 != 0) | (s.year % 400 == 0)) & (s.month == 2) & (s.day == 29)\n",
    "#mask = is_leap_and_29Feb(dates)\n",
    "#dates=dates[~mask]\n",
    "#print(dates)\n",
    "\n",
    "# Select Season\n",
    "if season_name == 'winter':\n",
    "    months=np.any([dates.month==12,dates.month==1,dates.month==2,dates.month==3],axis=0)\n",
    "if season_name == 'summer':\n",
    "    months=np.any([dates.month==6,dates.month==7,dates.month==8,dates.month==9],axis=0)\n",
    "\n",
    "dates2=dates[months]\n",
    "print(dates2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Conversion des longitudes : 0 - 360 --> -180 - 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def lonflip(da):\n",
    "    lon_name = 'lon'\n",
    "    da['_longitude_adjusted'] = xr.where(\n",
    "        da[lon_name] > 180,\n",
    "        da[lon_name] - 360,\n",
    "        da[lon_name])\n",
    "    da = (\n",
    "        da\n",
    "        .swap_dims({lon_name: '_longitude_adjusted'})\n",
    "        .sel(**{'_longitude_adjusted': sorted(da._longitude_adjusted)})\n",
    "        .drop(lon_name))\n",
    "    da = da.rename({'_longitude_adjusted': lon_name})\n",
    "    return da"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sélection des données sur le sous-domaine et la période choisis. Création d'un nouveau fichier netcdf des données quotidiennes sur le sous-domaine et la période retenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if domain_name=='natl':\n",
    "    data = lonflip(data0)\n",
    "if domain_name=='npac':\n",
    "    data = data0\n",
    "\n",
    "print(data)\n",
    "\n",
    "data_season = data.sel(lat=slice(latS,latN)).sel(lon=slice(lonW,lonE)).sel(time=dates2)\n",
    "print(data_season)\n",
    "\n",
    "lat  = data_season.lat.values\n",
    "lon  = data_season.lon.values\n",
    "time  = data_season.time.values\n",
    "\n",
    "if season_name == 'winter':\n",
    "    season1= str(data_season.time.values[130])[0:4]\n",
    "    season2= str(data_season.time.values[-1])[0:4]\n",
    "\n",
    "if season_name == 'summer':\n",
    "    season1= str(data_season.time.values[0])[0:4]\n",
    "    season2= str(data_season.time.values[-1])[0:4]\n",
    "\n",
    "print(' ----- Saving new seasonnal file from '+startday+ ' to '+endday+ ' on new domain  ----- ')\n",
    "infile1 = dir_res+varname+'_'+startday+'_'+endday+'_'+domain_name+'.nc'\n",
    "data_season.to_netcdf(infile1)\n",
    "print(' new daily seasonnal file over subdomain is here : ')\n",
    "print(infile1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vérification des dates (cellule à vider après vérification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with np.printoptions(threshold=np.inf):\n",
    "    print(time)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des anomalies quotidiennes sur le sous-domaine et la période retenus.\n",
    "Sauvegarde du fichier d'anomalies quotidiennes au format netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(' ----- Computing daily anomalies ----- ')\n",
    "data_anom = data_season.groupby('time.dayofyear') - data_season.groupby('time.dayofyear').mean('time')\n",
    "print(data_anom)\n",
    "print(' ----- Writing netcdf ----- ')\n",
    "infile2 = dir_res+varname+'_anom_'+startday+'_'+endday+'_'+domain_name+'.nc'\n",
    "data_anom.to_netcdf(infile2)\n",
    "print(' netcdf file of daily anomalies is here : ')\n",
    "print(infile2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 2 : étude des données quotidiennes sur un mois donné"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sélection des données (total et anomalie) pour 30 jours consécutifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if season_name == 'winter':\n",
    "    #date1='19891201'\n",
    "    #date2='19891230'\n",
    "    #date1='19900101'\n",
    "    #date2='19900130'\n",
    "    #date1='20100201'\n",
    "    #date2='20100302'\n",
    "    date1='20111201'\n",
    "    date2='20111230'\n",
    "    \n",
    "if season_name == 'summer':\n",
    "    date1='20030801'\n",
    "    date2='20030830'\n",
    "    \n",
    "data_month    = data_season.sel(time=slice(date1,date2))\n",
    "data_month_anom    = data_anom.sel(time=slice(date1,date2))\n",
    "\n",
    "z=data_month[varname]/var_div\n",
    "z_anom=data_month_anom[varname]/var_div\n",
    "\n",
    "time  = data_month.time.values\n",
    "\n",
    "time_str=[x for x in range(len(time))]\n",
    "date_str=[x for x in range(len(time))]\n",
    "\n",
    "for i in range(len(time)):\n",
    "\ttime_str[i] = str(time[i])\n",
    "\tdate_str[i] = time_str[i][0:10]\n",
    "    \n",
    "print(data_month)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Définition de la projection, fonction pour la découpe du contour des cartes en projection non rectangulaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "projection = ccrs.Orthographic(central_longitude=(lonW+lonE)/2, central_latitude=(latS+latN)/2)\n",
    "bounds = [(lonW, lonE, latS, latN)]\n",
    "\n",
    "def make_boundary_path(lon,lat):\n",
    "    lons,lats=np.meshgrid(lon,lat)\n",
    "    boundary_path = np.array([lons[-1,:],lats[-1,:]])\n",
    "    boundary_path = np.append(boundary_path,np.array([lons[::-1,-1],lats[::-1,-1]]),axis=1)\n",
    "    boundary_path = np.append(boundary_path,np.array([lons[1,::-1],lats[1,::-1]]),axis=1)\n",
    "    boundary_path = np.append(boundary_path,np.array([lons[:,1],lats[:,1]]),axis=1)\n",
    "    boundary_path = mpath.Path(np.swapaxes(boundary_path, 0, 1))\n",
    "    return boundary_path"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Domaine de tracé, échelles de valeurs et des titres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if varname=='z':\n",
    "    levels1 = np.arange(4800,6200,100)\n",
    "    plt_title1 = 'Geopotential height ('+units+') at 500 hPa : '+ str(date1)+'-'+str(date2)\n",
    "    levels2 = np.arange(-500,550,50)\n",
    "    plt_title2 = 'Geopotential height anomaly ('+units+') at 500 hPa : '+ str(date1)+'-'+str(date2)\n",
    "\n",
    "if varname=='msl':\n",
    "    levels1 = np.arange(980,1040,5)\n",
    "    plt_title1 = 'Mean Sea Level Pressure ('+units+') : '+ str(date1)+'-'+str(date2)\n",
    "    levels2 = np.arange(-25,27.5,2.5)\n",
    "    plt_title2 = 'Mean Sea Level Pressure anomaly ('+units+') : '+ str(date1)+'-'+str(date2)\n",
    "\n",
    "cmap1='jet'\n",
    "cmap2='RdBu_r'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des vignettes du champ quotidien pour les 30 jours consécutifs choisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title1, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "                   \n",
    "for i, ax in enumerate(axgr):\n",
    "    ax.coastlines()\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.set_title(date_str[i], fontsize=10)\n",
    "    p1 = ax.contourf(lon, lat, z[i,:,:], levels1, transform=ccrs.PlateCarree(), cmap=cmap1, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z[i,:,:], levels1, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "   \n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_'+str(date1)+'-'+str(date2)\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des vignettes de l'anomalie quotidienne pour les 30 jours consécutifs choisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "                   \n",
    "for i, ax in enumerate(axgr):\n",
    "    ax.coastlines()\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.set_title(date_str[i], fontsize=10)\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_'+str(date1)+'-'+str(date2)\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cartes individuelles des anomalies pour la séquence choisie (fichiers png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(time)):\n",
    "    #print(date_str[i])\n",
    "    fig = plt.figure(figsize=(8., 8.))\n",
    "    fig.suptitle(plt_title2, fontsize=16)\n",
    "    ax = fig.add_subplot(1,1,1, projection=projection)\n",
    "    ax.set_title(date_str[i], loc='center')\n",
    "    ax.coastlines()\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    cb = fig.colorbar(p1, orientation='horizontal', aspect=65, shrink=0.5, pad=0.05, extendrect='True')\n",
    "    cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "    figname=dir_anim+varname+'_anom_'+domain_name+'_'+season_name+'_'+date_str[i]\n",
    "    fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "print('png files are in the animation folder, ready to make the animation')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonction de création d'une animation à partir des fichiers png présents dans le dossier anim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_animation():\n",
    "    nbimages=len(time)\n",
    "    # create a tuple of display durations, one for each frame\n",
    "    first_last = 1000 #show the first and last frames for 1000 ms\n",
    "    standard_duration = 1000 #show all other frames for 1000 ms\n",
    "    durations = tuple([first_last] + [standard_duration] * (nbimages - 2) + [first_last])\n",
    "    # load all the static images into a list\n",
    "    images = [Image.open(image) for image in sorted(glob.glob('{}/*.png'.format(dir_anim)))]\n",
    "    # save as an animated gif\n",
    "    gif = images[0]\n",
    "    gif.info['duration'] = durations #ms per frame\n",
    "    gif.info['loop'] = 0 #how many times to loop (0=infinite)\n",
    "    gif.save(fp=gif_filepath, format='gif', save_all=True, append_images=images[1:])\n",
    "    # verify that the number of frames in the gif equals the number of image files and durations\n",
    "    Image.open(gif_filepath).n_frames == len(images) == len(durations)\n",
    "    # clean png\n",
    "    os.chdir(dir_anim)\n",
    "    for f in glob.glob(\"*.png\"):\n",
    "        os.remove(f)\n",
    "    os.chdir(\"../\")\n",
    "    return Image"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Animation des anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gif_filepath = dir_anim+varname+'_anom_'+domain_name+'_'+season_name+'_'+str(date1)+'-'+str(date2)+'.gif'\n",
    "make_animation()\n",
    "IPdisplay.Image(url=gif_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 3 : décomposition des données en temps et en espace (analyse en composantes principales, ACP)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ouverture (via netcdf4) des données quotidennes, domaine Nord Atlantique, période DJFM 1957-2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = infile1\n",
    "ncin = Dataset(filename, 'r')\n",
    "lons = ncin.variables['lon'][:]\n",
    "lats = ncin.variables['lat'][:]\n",
    "var = ncin.variables[varname][:]\n",
    "ncin.close()\n",
    "\n",
    "filename = infile2\n",
    "ncin = Dataset(filename, 'r')\n",
    "lons = ncin.variables['lon'][:]\n",
    "lats = ncin.variables['lat'][:]\n",
    "var_anom = ncin.variables[varname][:]\n",
    "ncin.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Réalisation de l'ACP. Avant de réaliser l'ACP on applique une pondération. En effet, sur une grille régulière lat/lon qui ne conserve pas les aires, chaque point de grille n'est pas représentatif de la même surface. Ainsi, si aucune pondération n'est faite avant l'ACP il y aura un problème de distortion aux hautes latitudes. On applique donc en chaque point de grille une pondération consistant à diviser le champ par la racine carrée du cosinus de la latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coslat = np.cos(np.deg2rad(lats)).clip(0., 1.)\n",
    "wgts = np.sqrt(coslat)[..., np.newaxis]\n",
    "solver = Eof(var_anom, weights=wgts, center=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé du pourcentage de variance expliqué par chaque composante principale (1-15). Plus de 80% de la variabilité totale sont expliqués par les 10 premières composantes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "varfrac = solver.varianceFraction()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "fig.suptitle('EOF analysis : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "\n",
    "eof_num = range(1, 16)\n",
    "plt.bar(eof_num, varfrac[0:15], width=0.5)\n",
    "plt.axhline(0, color='k')\n",
    "plt.xticks(range(1, 16))\n",
    "plt.title('Fraction of the total variance represented by each EOF')\n",
    "plt.xlabel('EOF #')\n",
    "plt.ylabel('Variance Fraction')\n",
    "plt.xlim(1, 15)\n",
    "plt.ylim(np.min(varfrac), np.max(varfrac)+0.01)\n",
    "plt.show()\n",
    "\n",
    "print(varfrac[0:10].sum())\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_varfrac'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Récupération des 10 premiers vecteurs propres (EOFs, structures spatiales) exprimés comme la covariance entre les séries temporelles des composantes principales (PCs) et les séries temporelles des données d'entrée à chaque point de grille.\n",
    "Récupération des séries temporelles des composantes principales normalisées (PCs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n=10\n",
    "eofs = solver.eofsAsCovariance(neofs=n)\n",
    "pcs = solver.pcs(npcs=n, pcscaling=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des structures spatiales (EOFs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if varname=='z':\n",
    "    clevs = np.linspace(-1000, 1000, 11)\n",
    "if varname=='msl':\n",
    "    clevs = np.linspace(-1000, 1000, 21)\n",
    "\n",
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "fig.suptitle('EOFs : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(2, int(n/2)),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "                   \n",
    "for i, ax in enumerate(axgr):\n",
    "    ax.coastlines()\n",
    "    ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.set_title('EOF'+str(i+1)+' ('+str(int(varfrac[i]*100))+'%)', fontsize=10, loc='center')\n",
    "    cf = ax.contourf(lons, lats, eofs[i], clevs, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    c = ax.contour(lons, lats, eofs[i], levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(cf)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_eofs'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des 3 premières structures spatiales (EOFs) et des séries temporelles associées (PCs). On change les signes des EOFs et PCs 2 pour avoir les correspondances suivantes :\n",
    "EOF1 > 0 : NAO+ ; EOF1 < 0 : NAO-\n",
    "EOF2 > 0 : blocage ; EOF2 < 0 : antiblocage\n",
    "EOF3 > 0 : dorsale atlantique ; EOF3 < 0 : minimum atlantique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eof1=eofs[0]\n",
    "eof2=eofs[1]*(-1)\n",
    "eof3=eofs[2]\n",
    "\n",
    "pc1=pcs[:,0]\n",
    "pc2=pcs[:,1]*(-1)\n",
    "pc3=pcs[:,2]\n",
    "\n",
    "def plot_pc(ax):\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Normalized Units')\n",
    "    plt.axhline(0, color='k')\n",
    "    ax.set_ylim(-4, 4)\n",
    "    return ax\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "fig.suptitle('EOFs and PCs : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "ax = fig.add_subplot(3, 2, 1, projection=projection)\n",
    "plt.title('EOF1 ('+str(int(varfrac[0]*100))+'%)', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, eof1, levels=clevs, cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, eof1, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Covariance', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 2)\n",
    "plot_pc(ax)\n",
    "plt.title('PC1 Time Series')\n",
    "plt.plot(pc1, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 3, projection=projection)\n",
    "plt.title('EOF2 ('+str(int(varfrac[1]*100))+'%)', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, eof2, levels=clevs, cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, eof2, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Covariance', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 4)\n",
    "plot_pc(ax)\n",
    "plt.title('PC2 Time Series')\n",
    "plt.plot(pc2, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 5, projection=projection)\n",
    "plt.title('EOF3 ('+str(int(varfrac[2]*100))+'%)', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, eof3, levels=clevs, cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, eof3, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Covariance', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 6)\n",
    "plot_pc(ax)\n",
    "plt.title('PC3 Time Series')\n",
    "plt.plot(pc3, color='k', linewidth=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_eofs_pcs'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonction de tracé pour l'espace des phases 2D défini par PC1 et PC2 et dans l'espace des phases 3D défini par PC1 PC2 et PC3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_phase_space2d(ax):\n",
    "    plt.title('')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.xlim(-4, 4)\n",
    "    plt.ylim(-4, 4)\n",
    "    plt.axvline(0, color='k', linestyle='--')\n",
    "    plt.axhline(0, color='k', linestyle='--')\n",
    "    return ax\n",
    "\n",
    "def plot_phase_space3d(ax):\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_zlabel('PC3')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé du nuage de points des séries temporelles dans l'espace des phases défini par PC1 et PC2 (+ densité avec la fonction gaussian_kde de scipy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "fig.suptitle('PC1 and PC2 phase space density', fontsize=14)\n",
    "plot_phase_space2d(ax)\n",
    "xy = np.vstack([pc1,pc2])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "#ax.scatter(pc1,pc2, s=10, color = 'r')\n",
    "ax.scatter(pc1, pc2, cmap='jet', c=z, s=10)\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc12_density'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé du nuage de points des séries temporelles dans l'espace des phases défini par PC1 PC2 et PC3 (projection=3D, + densité avec la fonction gaussian_kde de scipy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.suptitle('PC1 PC2 and PC3 phase space', fontsize=14)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plot_phase_space3d(ax)\n",
    "xyz = np.vstack([pc1,pc2,pc3])\n",
    "z = gaussian_kde(xyz)(xyz)\n",
    "#ax.scatter(pc1,pc2,pc3, s=10, color = 'r')\n",
    "ax.scatter(pc1, pc2, pc3, cmap='jet', c=z, s=10)\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc123_density'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 4 : classification en 4 classes = régimes (méthode k-means)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Les régimes de temps sont des attracteurs dans l'espace climatique. Pour les mettre en évidence on utilise une méthode de classification (\"clustering\") de type Kmeans. Cette méthode nécessite un choix a priori d'un nombre de classes que l'on fixe à 4 (4 attracteurs dans l'espace climatique). La classification est faite dans l'espace des phases des 10 PCs issu de l'ACP."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Clustering - méthode K-means. L'algorithme est exécuté 100 fois avec différents \"centroid seeds\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcs = np.array([pc1,pc2,pc3,pcs[:,3],pcs[:,4],pcs[:,5],pcs[:,6],pcs[:,7],pcs[:,8],pcs[:,9]])\n",
    "pcs=pcs.transpose()\n",
    "\n",
    "# Number of clusters\n",
    "kmeans = KMeans(n_clusters=4,n_init=100)\n",
    "# Fitting the input data\n",
    "kmeans = kmeans.fit(pcs)\n",
    "# Getting the cluster labels\n",
    "cluster = kmeans.predict(pcs)\n",
    "# Centroid values\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "print(cluster)\n",
    "print(cluster.shape)\n",
    "print(centroids.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Comptage du nombre de jours par cluster et des fréquences (nombre de jours du cluster divisé par nombre de jours total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nc1=list(cluster[:]).count(0)\n",
    "nc2=list(cluster[:]).count(1)\n",
    "nc3=list(cluster[:]).count(2)\n",
    "nc4=list(cluster[:]).count(3)\n",
    "\n",
    "f1=int(nc1/cluster.shape[0]*100)\n",
    "f2=int(nc2/cluster.shape[0]*100)\n",
    "f3=int(nc3/cluster.shape[0]*100)\n",
    "f4=int(nc4/cluster.shape[0]*100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Création du tableau des couleurs selon le numéro de cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors=[\"\"]*len(cluster)\n",
    "couleur=[\"blue\",\"red\",\"green\",\"orange\"]\n",
    "for i in range(len(cluster)):\n",
    " colors[i]=couleur[cluster[i]]\n",
    "\n",
    "label=couleur[0]+' : '+str(nc1)+' ('+str(f1)+'%)'+', '+couleur[1]+' : '+str(nc2)+' ('+str(f2)+'%)'+', '+couleur[2]+' : '+str(nc3)+' ('+str(f3)+'%)'+', '+couleur[3]+' : '+str(nc4)+' ('+str(f4)+'%)'\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé du nuage de points des séries temporelles dans l'espace des phases défini par PC1 et PC2 après clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "fig.suptitle('PC1 and PC2 phase space (4 clusters)', fontsize=14)\n",
    "plot_phase_space2d(ax)\n",
    "plt.scatter(pc1, pc2, c=colors, s=10, label=label)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c=couleur, s=2000, alpha=1, marker='+');\n",
    "\n",
    "patch1 = mpatches.Patch(color=couleur[0], label='Cluster 1 : '+str(nc1)+' ('+str(f1)+'%)')\n",
    "patch2 = mpatches.Patch(color=couleur[1], label='Cluster 2 : '+str(nc2)+' ('+str(f2)+'%)')\n",
    "patch3 = mpatches.Patch(color=couleur[2], label='Cluster 3 : '+str(nc3)+' ('+str(f3)+'%)')\n",
    "patch4 = mpatches.Patch(color=couleur[3], label='Cluster 4 : '+str(nc4)+' ('+str(f4)+'%)')\n",
    "all_handles = (patch1, patch2, patch3, patch4)\n",
    "leg = ax.legend(handles=all_handles, loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc12_clustering'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé du nuage de points des séries temporelles dans l'espace des phases défini par PC1 PC2 et PC3 après clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.suptitle('PC1 PC2 and PC3 phase space (4 clusters)', fontsize=14)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plot_phase_space3d(ax)\n",
    "ax.scatter(pc1, pc2, pc3, c=colors, s=10, label=label)\n",
    "ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], c=couleur, s=2000, alpha=1, marker='+')\n",
    "\n",
    "patch1 = mpatches.Patch(color=couleur[0], label='Cluster 1 : '+str(nc1)+' ('+str(f1)+'%)')\n",
    "patch2 = mpatches.Patch(color=couleur[1], label='Cluster 2 : '+str(nc2)+' ('+str(f2)+'%)')\n",
    "patch3 = mpatches.Patch(color=couleur[2], label='Cluster 3 : '+str(nc3)+' ('+str(f3)+'%)')\n",
    "patch4 = mpatches.Patch(color=couleur[3], label='Cluster 4 : '+str(nc4)+' ('+str(f4)+'%)')\n",
    "all_handles = (patch1, patch2, patch3, patch4)\n",
    "leg = ax.legend(handles=all_handles, loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc123_clustering'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 5 : obtention des régimes de temps"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des composites du champ pour chaque cluster. Pour chaque cluster, on fait la moyenne du champ pour tous jours qui sont classés dans ce cluster --> 4 régimes de temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_cluster1=np.any([cluster==0],axis=0)\n",
    "id_cluster2=np.any([cluster==1],axis=0)\n",
    "id_cluster3=np.any([cluster==2],axis=0)\n",
    "id_cluster4=np.any([cluster==3],axis=0)\n",
    "\n",
    "print(id_cluster1)\n",
    "print(id_cluster2)\n",
    "print(id_cluster3)\n",
    "print(id_cluster4)\n",
    "\n",
    "mean_c1 = var[id_cluster1,:,:].mean(axis=0)/var_div\n",
    "mean_c2 = var[id_cluster2,:,:].mean(axis=0)/var_div\n",
    "mean_c3 = var[id_cluster3,:,:].mean(axis=0)/var_div\n",
    "mean_c4 = var[id_cluster4,:,:].mean(axis=0)/var_div\n",
    "\n",
    "mean_c1_anom = var_anom[id_cluster1,:,:].mean(axis=0)/var_div\n",
    "mean_c2_anom = var_anom[id_cluster2,:,:].mean(axis=0)/var_div\n",
    "mean_c3_anom = var_anom[id_cluster3,:,:].mean(axis=0)/var_div\n",
    "mean_c4_anom = var_anom[id_cluster4,:,:].mean(axis=0)/var_div"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des 4 régimes de temps (anomalie en couleur et champ moyen en isolignes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if varname=='z':\n",
    "    clevs = np.linspace(5000, 6000, 11)\n",
    "    clevs_anom = np.linspace(-150, 150, 11)\n",
    "if varname=='msl':\n",
    "    clevs = np.linspace(990, 1020, 15)\n",
    "    clevs_anom = np.linspace(-8, 8, 17)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "fig.suptitle('Weather regimes : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1, projection=projection)\n",
    "plt.title('Regime 1 (freq = '+str(f1)+'%)', fontsize=10, loc='center', color=couleur[0])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c1_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c1, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2, projection=projection)\n",
    "plt.title('Regime 2 (freq = '+str(f2)+'%)', fontsize=10, loc='center', color=couleur[1])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c2_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c2, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3, projection=projection)\n",
    "plt.title('Regime 3 (freq = '+str(f3)+'%)', fontsize=10, loc='center', color=couleur[2])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c3_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c3, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4, projection=projection)\n",
    "plt.title('Regime 4 (freq = '+str(f4)+'%)', fontsize=10, loc='center', color=couleur[3])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c4_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c4, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_'+'regimes'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if domain_name=='natl' and season_name=='winter':\n",
    "    r1=input(\"Parmi les propositions suivantes nommer le régime 1 : NAO+ / NAO- / Dorsale Atl / Blocage \")\n",
    "    r2=input(\"Parmi les propositions suivantes nommer le régime 2 : NAO+ / NAO- / Dorsale Atl / Blocage \")\n",
    "    r3=input(\"Parmi les propositions suivantes nommer le régime 3 : NAO+ / NAO- / Dorsale Atl / Blocage \")\n",
    "    r4=input(\"Parmi les propositions suivantes nommer le régime 4 : NAO+ / NAO- / Dorsale Atl / Blocage \")\n",
    "\n",
    "if domain_name=='npac' and season_name=='winter':\n",
    "    r1=input(\"Parmi les propositions suivantes nommer le régime 1 : Alaskan Ridge / Arctic low / Arctic high / Pac through \")\n",
    "    r2=input(\"Parmi les propositions suivantes nommer le régime 2 : Alaskan Ridge / Arctic low / Arctic high / Pac through \")\n",
    "    r3=input(\"Parmi les propositions suivantes nommer le régime 3 : Alaskan Ridge / Arctic low / Arctic high / Pac through \")\n",
    "    r4=input(\"Parmi les propositions suivantes nommer le régime 4 : Alaskan Ridge / Arctic low / Arctic high / Pac through \")\n",
    "\n",
    "if domain_name=='natl' and season_name=='summer':\n",
    "    r1=input(\"Parmi les propositions suivantes nommer le régime 1 : Zonal / Anticyclone Gro / Blocage été / Thalweg Atl \")\n",
    "    r2=input(\"Parmi les propositions suivantes nommer le régime 2 : Zonal / Anticyclone Gro / Blocage été / Thalweg Atl \")\n",
    "    r3=input(\"Parmi les propositions suivantes nommer le régime 3 : Zonal / Anticyclone Gro / Blocage été / Thalweg Atl \")\n",
    "    r4=input(\"Parmi les propositions suivantes nommer le régime 4 : Zonal / Anticyclone Gro / Blocage été / Thalweg Atl \")\n",
    "  \n",
    "if domain_name=='npac' and season_name=='summer':\n",
    "    r1=input(\"Nommer le régime 1 : \")\n",
    "    r2=input(\"Nommer le régime 2 : \")\n",
    "    r3=input(\"Nommer le régime 3 : \")\n",
    "    r4=input(\"Nommer le régime 4 : \")\n",
    "\n",
    "regime=[r1, r2, r3, r4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 6 : temps sensible associé aux régimes de temps"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ouverture du fichier de réanalyses quotidiennes ERA5 de température à 2m (T2m) et de précipitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_t0    = xr.open_dataset(dir_data+'t2m_eur_19790101_20191231.nc')\n",
    "data_tp0    = xr.open_dataset(dir_data+'tp_eur_19790101_20191231.nc')\n",
    "print(data_t0)\n",
    "print(data_tp0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sélection de la sous-periode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if season_name == 'winter':\n",
    "    d1='1979-12-01T09'\n",
    "    d2='2018-03-31T09'\n",
    "\n",
    "if season_name == 'summer':\n",
    "    d1='1979-06-01T09'\n",
    "    d2='2018-09-30T09'\n",
    "\n",
    "    # Date index from startday to endday\n",
    "d = pd.date_range(d1, d2, freq='D')\n",
    "print(d)\n",
    "\n",
    "# Remove 29/02\n",
    "#mask = is_leap_and_29Feb(d)\n",
    "#d=d[~mask]\n",
    "#print(d)\n",
    "\n",
    "# Select Season\n",
    "if season_name == 'winter':\n",
    "    mm=np.any([d.month==12,d.month==1,d.month==2,d.month==3],axis=0)\n",
    "if season_name == 'summer':\n",
    "    mm=np.any([d.month==6,d.month==7,d.month==8,d.month==9],axis=0)\n",
    "\n",
    "dd2=d[mm]\n",
    "print(dd2)\n",
    "\n",
    "data_t    = xr.open_dataset(dir_data+'t2m_eur_19790101_20191231.nc').sel(time=slice(d1,d2))\n",
    "data_t    = data_t.sel(time=dd2)\n",
    "data_tp    = xr.open_dataset(dir_data+'tp_eur_19790101_20191231.nc').sel(time=slice(d1,d2))\n",
    "data_tp    = data_tp.sel(time=dd2)\n",
    "\n",
    "\n",
    "print(data_t0)\n",
    "print(data_tp0)\n",
    "print(data_t)\n",
    "print(data_tp)\n",
    "\n",
    "lat_t  = data_t.latitude.values\n",
    "lon_t  = data_t.longitude.values\n",
    "time_t  = data_t.time.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des anomalies quotidiennes de T2m et de précipitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(' ----- Computing daily anomalies of T2m ----- ')\n",
    "data_t_anom = data_t.groupby('time.dayofyear') - data_t.groupby('time.dayofyear').mean('time')\n",
    "print(' ----- Computing daily anomalies of precipitation ----- ')\n",
    "data_tp_anom = data_tp.groupby('time.dayofyear') - data_tp.groupby('time.dayofyear').mean('time')\n",
    "\n",
    "t2m_anom=data_t_anom['t2m']\n",
    "tp_anom=data_tp_anom['tp']*1000\n",
    "\n",
    "print(t2m_anom.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des composites de T2m et de précipitations pour chaque cluster. Pour chaque cluster, on fait la moyenne du champ pour les jours qui \"tombent\" dans ce cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cluster.shape)\n",
    "print(dates2)\n",
    "\n",
    "if season_name=='winter':\n",
    "    if var_text=='Z500':\n",
    "        dd1='1979-12-01T18'\n",
    "        dd2='2018-03-31T18'\n",
    "    if var_text=='MSLP':\n",
    "        dd1='1979-12-01T09'\n",
    "        dd2='2018-03-31T09'\n",
    "        \n",
    "if season_name=='summer':\n",
    "    if var_text=='Z500':\n",
    "        dd1='1979-06-01T18'\n",
    "        dd2='2018-09-30T18'\n",
    "    if var_text=='MSLP':\n",
    "        dd1='1979-06-01T09'\n",
    "        dd2='2018-09-30T09'\n",
    "        \n",
    "index_y=np.all([dates2>=dd1, dates2<=dd2], axis=0)\n",
    "cluster_t=cluster[index_y]\n",
    "print(cluster_t.shape)\n",
    "\n",
    "id_cluster1_t=np.any([cluster_t==0],axis=0)\n",
    "id_cluster2_t=np.any([cluster_t==1],axis=0)\n",
    "id_cluster3_t=np.any([cluster_t==2],axis=0)\n",
    "id_cluster4_t=np.any([cluster_t==3],axis=0)\n",
    "\n",
    "mean_c1_anom_t = t2m_anom[id_cluster1_t,:,:].mean(axis=0)\n",
    "mean_c2_anom_t = t2m_anom[id_cluster2_t,:,:].mean(axis=0)\n",
    "mean_c3_anom_t = t2m_anom[id_cluster3_t,:,:].mean(axis=0)\n",
    "mean_c4_anom_t = t2m_anom[id_cluster4_t,:,:].mean(axis=0)\n",
    "\n",
    "mean_c1_anom_tp = tp_anom[id_cluster1_t,:,:].mean(axis=0)\n",
    "mean_c2_anom_tp = tp_anom[id_cluster2_t,:,:].mean(axis=0)\n",
    "mean_c3_anom_tp = tp_anom[id_cluster3_t,:,:].mean(axis=0)\n",
    "mean_c4_anom_tp = tp_anom[id_cluster4_t,:,:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des composites des anomalies de T2m pour chaque régime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#projection2=ccrs.EuroPP()\n",
    "#projection2=ccrs.PlateCarree()\n",
    "projection2=ccrs.NearsidePerspective(central_longitude=5.0, central_latitude=55.0)\n",
    "bounds = [(-20, 30, 30, 80)]\n",
    "\n",
    "levs_t_anom = np.linspace(-5, 5, 21)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "fig.suptitle('Composites of 2-meter temperature anomalies : ERA5 DJFM 1979-2018', fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1, projection=projection2)\n",
    "plt.title(regime[0], fontsize=10, loc='center', color=couleur[0])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c1_anom_t, levels=levs_t_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (°C)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2, projection=projection2)\n",
    "plt.title(regime[1], fontsize=10, loc='center', color=couleur[1])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c2_anom_t, levels=levs_t_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (°C)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3, projection=projection2)\n",
    "plt.title(regime[2], fontsize=10, loc='center', color=couleur[2])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c3_anom_t, levels=levs_t_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (°C)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4, projection=projection2)\n",
    "plt.title(regime[3], fontsize=10, loc='center', color=couleur[3])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c4_anom_t, levels=levs_t_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (°C)', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_t2m_composite_DJFM'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des composites des anomalies de précipitations pour chaque régime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmap3='BrBG'\n",
    "\n",
    "levs_tp_anom = np.linspace(-1, 1, 21)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "fig.suptitle('Composites of precipitation anomalies : ERA5 1979-2018', fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1, projection=projection2)\n",
    "plt.title(regime[0], fontsize=10, loc='center', color=couleur[0])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c1_anom_tp, levels=levs_tp_anom, \n",
    "                 cmap=cmap3, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (mm/day)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2, projection=projection2)\n",
    "plt.title(regime[1], fontsize=10, loc='center', color=couleur[1])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c2_anom_tp, levels=levs_tp_anom, \n",
    "                 cmap=cmap3, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (mm/day)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3, projection=projection2)\n",
    "plt.title(regime[2], fontsize=10, loc='center', color=couleur[2])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c3_anom_tp, levels=levs_tp_anom, \n",
    "                 cmap=cmap3, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (mm/day)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4, projection=projection2)\n",
    "plt.title(regime[3], fontsize=10, loc='center', color=couleur[3])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c4_anom_tp, levels=levs_tp_anom, \n",
    "                 cmap=cmap3, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (mm/day)', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_precip_composite_DJFM'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 7 : étude des occurrences saisonnières des régimes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul du nombre d'occurences de régimes par saison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find indexes for end of season\n",
    "time_str = [x for x in range(len(dates2))]\n",
    "date_str = [x for x in range(len(dates2))]\n",
    "for i in range(len(dates2)):\n",
    "    time_str[i] = str(dates2[i])\n",
    "    date_str[i] = time_str[i][5:10]\n",
    "\n",
    "if season_name == 'winter':\n",
    "    index_end = [i for i, value in enumerate(date_str) if value == '03-31']\n",
    "\n",
    "if season_name == 'summer':\n",
    "    index_end = [i for i, value in enumerate(date_str) if value == '08-31']\n",
    "    \n",
    "print(index_end)\n",
    "print(len(index_end))\n",
    "\n",
    "seasons= [x for x in range(int(season1),int(season2)+1)]\n",
    "cl1_count=np.zeros(len(index_end))\n",
    "cl2_count=np.zeros(len(index_end))\n",
    "cl3_count=np.zeros(len(index_end))\n",
    "cl4_count=np.zeros(len(index_end))\n",
    "\n",
    "# Cluster1\n",
    "cl1_count[0]=list(cluster[0:index_end[0]+1]).count(0)\n",
    "for i in range(1,len(index_end)):\n",
    " cl1_count[i]=list(cluster[index_end[i-1]+1:index_end[i]+1]).count(0)\n",
    " \n",
    "# Cluster2\n",
    "cl2_count[0]=list(cluster[0:index_end[0]+1]).count(1)\n",
    "for i in range(1,len(index_end)):\n",
    " cl2_count[i]=list(cluster[index_end[i-1]+1:index_end[i]+1]).count(1)\n",
    "\n",
    "# Cluster3\n",
    "cl3_count[0]=list(cluster[0:index_end[0]+1]).count(2)\n",
    "for i in range(1,len(index_end)):\n",
    " cl3_count[i]=list(cluster[index_end[i-1]+1:index_end[i]+1]).count(2)\n",
    "\n",
    "# Cluster4\n",
    "cl4_count[0]=list(cluster[0:index_end[0]+1]).count(3)\n",
    "for i in range(1,len(index_end)):\n",
    " cl4_count[i]=list(cluster[index_end[i-1]+1:index_end[i]+1]).count(3)\n",
    "\n",
    "print(seasons)\n",
    "print(cl1_count)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des occurences de régimes par saison et des tendances linéaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate trends\n",
    "X = np.reshape(seasons, (len(seasons), 1))\n",
    "\n",
    "y = cl1_count\n",
    "model = LinearRegression()\n",
    "model.fit(X, cl1_count)\n",
    "trend_cl1 = model.predict(X)\n",
    "\n",
    "y = cl2_count\n",
    "model = LinearRegression()\n",
    "model.fit(X, cl2_count)\n",
    "trend_cl2 = model.predict(X)\n",
    "\n",
    "y = cl3_count\n",
    "model = LinearRegression()\n",
    "model.fit(X, cl3_count)\n",
    "trend_cl3 = model.predict(X)\n",
    "\n",
    "y = cl4_count\n",
    "model = LinearRegression()\n",
    "model.fit(X, cl4_count)\n",
    "trend_cl4 = model.predict(X)\n",
    "\n",
    "def plot_regimes_occ(ax):\n",
    " plt.xlabel('Year')\n",
    " plt.ylabel('Number of days')\n",
    " plt.xlim(int(season1), int(season2))\n",
    " plt.ylim(0, 85)\n",
    " plt.axvline(1960, color='grey', linestyle='--')\n",
    " plt.axvline(1970, color='grey', linestyle='--')\n",
    " plt.axvline(1980, color='grey', linestyle='--')\n",
    " plt.axvline(1990, color='grey', linestyle='--')\n",
    " plt.axvline(2000, color='grey', linestyle='--')\n",
    " plt.axvline(2010, color='grey', linestyle='--')\n",
    " return ax\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "fig.suptitle('Weather regime occurrences : '\n",
    "             +var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "plt.title(regime[0]+' (mean = '+str(int(cl1_count.mean()))+'d)', fontsize=10, loc='center', color=couleur[0])\n",
    "plot_regimes_occ(ax)\n",
    "colormat=np.where(cl1_count>cl1_count.mean(), 'red','blue')\n",
    "plt.bar(seasons,cl1_count-cl1_count.mean(), bottom=cl1_count.mean(), color=colormat, linewidth=1)\n",
    "plt.plot(seasons,trend_cl1, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "plt.title(regime[1]+' (mean = '+str(int(cl2_count.mean()))+'d)', fontsize=10, loc='center', color=couleur[1])\n",
    "plot_regimes_occ(ax)\n",
    "colormat=np.where(cl2_count>cl2_count.mean(), 'red','blue')\n",
    "plt.bar(seasons,cl2_count-cl2_count.mean(), bottom=cl2_count.mean(), color=colormat, linewidth=1)\n",
    "plt.plot(seasons,trend_cl2, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "plt.title(regime[2]+' (mean = '+str(int(cl3_count.mean()))+'d)', fontsize=10, loc='center', color=couleur[2])\n",
    "plot_regimes_occ(ax)\n",
    "colormat=np.where(cl3_count>cl3_count.mean(), 'red','blue')\n",
    "plt.bar(seasons,cl3_count-cl3_count.mean(), bottom=cl3_count.mean(), color=colormat, linewidth=1)\n",
    "plt.plot(seasons,trend_cl3, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "plt.title(regime[3]+' (mean = '+str(int(cl4_count.mean()))+'d)', fontsize=10, loc='center', color=couleur[3])\n",
    "plot_regimes_occ(ax)\n",
    "colormat=np.where(cl4_count>cl4_count.mean(), 'red','blue')\n",
    "plt.bar(seasons,cl4_count-cl4_count.mean(), bottom=cl4_count.mean(), color=colormat, linewidth=1)\n",
    "plt.plot(seasons,trend_cl4, color='k', linewidth=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_regimes_occurrence'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Classement des occurences de régimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Classement \"+regime[0])\n",
    "print(np.sort(cl1_count))\n",
    "rank=[]\n",
    "for i in np.argsort(cl1_count):\n",
    "    rank.append(seasons[i]) \n",
    "print(rank)\n",
    "print(\"****************************************************\")\n",
    "\n",
    "print(\"Classement \"+regime[1])\n",
    "print(np.sort(cl2_count))\n",
    "rank=[]\n",
    "for i in np.argsort(cl2_count):\n",
    "    rank.append(seasons[i]) \n",
    "print(rank)\n",
    "print(\"****************************************************\")\n",
    "\n",
    "print(\"Classement \"+regime[2])\n",
    "print(np.sort(cl3_count))\n",
    "rank=[]\n",
    "for i in np.argsort(cl3_count):\n",
    "    rank.append(seasons[i]) \n",
    "print(rank)\n",
    "print(\"****************************************************\")\n",
    "\n",
    "print(\"Classement \"+regime[3])\n",
    "print(np.sort(cl4_count))\n",
    "rank=[]\n",
    "for i in np.argsort(cl4_count):\n",
    "    rank.append(seasons[i]) \n",
    "print(rank)\n",
    "print(\"****************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 8 : retour sur une saison particulière"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Choix de la saison (Attention, pour un hiver N-N+1, entrer N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if season_name == 'winter':\n",
    "    choix=input('hiver ? ')\n",
    "    leap_year=calendar.isleap(int(choix)+1)\n",
    "    if var_text=='Z500':\n",
    "        date1=choix+'-12-01T18'\n",
    "    if var_text=='MSLP':\n",
    "        date1=choix+'-12-01T09'\n",
    "    idx_date1=dates2.get_loc(date1, method ='ffill')\n",
    "    if leap_year:\n",
    "        print('Année bisextile')\n",
    "        idx_date2=idx_date1+122\n",
    "    else:\n",
    "        idx_date2=idx_date1+121\n",
    "    \n",
    "if season_name == 'summer':\n",
    "    choix=input('été ? ')\n",
    "    if var_text=='Z500':\n",
    "        date1=choix+'-06-01T18'\n",
    "    if var_text=='MSLP':\n",
    "        date1=choix+'-06-01T09'\n",
    "    idx_date2=idx_date1+121"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Gestion des dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pc_dates=dates2[idx_date1:idx_date2]\n",
    "print(pc_dates[0])\n",
    "print(pc_dates[-1])\n",
    "print(pc_dates.shape)\n",
    "\n",
    "date2=pc_dates[-1]\n",
    "date2=str(pc_dates[-1])\n",
    "date2=date2[0:10]\n",
    "\n",
    "time_str = [x for x in range(len(pc_dates))]\n",
    "date_str = [x for x in range(len(pc_dates))]\n",
    "date_str_title = [x for x in range(len(pc_dates))]\n",
    "\n",
    "for i in range(len(pc_dates)):\n",
    "    time_str[i] = str(pc_dates[i])\n",
    "    date_str_title[i] = time_str[i][0:10]\t\n",
    "    date_str[i] = time_str[i][5:10]\n",
    "    \n",
    "leap_year=calendar.isleap(int(time_str[-1][0:4]))\n",
    "if leap_year:\n",
    "    print('Année bisextile')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Selection des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_month_anom    = data_anom.sel(time=slice(date1,date2))\n",
    "z_anom=data_month_anom[varname]/var_div\n",
    "print(z_anom.shape)\n",
    "\n",
    "time  = data_month_anom.time.values\n",
    "lat  = data_month_anom.lat.values\n",
    "lon  = data_month_anom.lon.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vignettes d'anomalies quotidiennes avec attribution du cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if varname=='zg500':\n",
    "    plt_title2 = 'Geopotential height anomaly ('+units+') at 500 hPa : '+ str(date1)+'-'+str(date2)\n",
    "\n",
    "if varname=='slp':\n",
    "    plt_title2 = 'Mean Sea Level Pressure anomaly ('+units+') : '+ str(date1)+'-'+str(date2)\n",
    "\n",
    "#\n",
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "                   \n",
    "for i, ax in enumerate(axgr):\n",
    "    reg=cluster[idx_date1+i] # régime\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_title(date_str_title[i]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i])\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_cluster_'+str(date1)+'-'+str(date2)+'_1'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "\n",
    "#\n",
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "\n",
    "for i, ax in enumerate(axgr):\n",
    "    reg=cluster[idx_date1+30+i] # régime\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_title(date_str_title[i+30]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i+30])\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i+30,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i+30,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_cluster_'+str(date1)+'-'+str(date2)+'_2'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "\n",
    "#\n",
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "\n",
    "for i, ax in enumerate(axgr):\n",
    "    reg=cluster[idx_date1+60+i] # régime\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_title(date_str_title[i+60]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i+60])\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i+60,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i+60,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_cluster_'+str(date1)+'-'+str(date2)+'_3'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "\n",
    "#\n",
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "\n",
    "for i, ax in enumerate(axgr):\n",
    "    reg=cluster[idx_date1+90+i] # régime\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_title(date_str_title[i+90]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i+90])\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i+90,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i+90,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_cluster_'+str(date1)+'-'+str(date2)+'_4'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cartes individuelles des anomalies avec attribution du cluster (fichiers png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(time)):\n",
    "    #print(date_str[i])\n",
    "    reg=cluster[idx_date1+i]\n",
    "    if reg==0:\n",
    "            composite  = mean_c1_anom\n",
    "    if reg==1:\n",
    "            composite  = mean_c2_anom\n",
    "    if reg==2:\n",
    "            composite  = mean_c3_anom\n",
    "    if reg==3:\n",
    "            composite  = mean_c4_anom\n",
    "    fig = plt.figure(figsize=(15., 5.))\n",
    "    fig.suptitle(plt_title2, fontsize=16)\n",
    "    \n",
    "    ax = fig.add_subplot(1,2,1, projection=projection)\n",
    "    ax.set_title(date_str_title[i]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i])\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    cb = fig.colorbar(p1, orientation='horizontal', aspect=65, shrink=0.5, pad=0.05, extendrect='True')\n",
    "    cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "    \n",
    "    ax = fig.add_subplot(1,2,2, projection=projection)\n",
    "    plt.title(regime[reg]+' composite', fontsize=10, loc='center', color=colors[idx_date1+i])\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    cf = ax.contourf(lons, lats, composite, levels=clevs_anom, \n",
    "                     cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "    c = ax.contour(lons, lats, mean_c4, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "    ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "    cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=0.5, pad=0.05, extendrect='True')\n",
    "    cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "    figname=dir_anim+varname+'_anom_cluster'+domain_name+'_'+season_name+'_'+date_str[i]\n",
    "    fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "print('png files are in the animation folder, ready to make the animation')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Animation de la saison avec composite du régime en vis-à-vis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gif_filepath = dir_anim+varname+'_anom_cluster_'+domain_name+'_'+season_name+'_'+str(date1)+'-'+str(date2)+'.gif'\n",
    "make_animation()\n",
    "IPdisplay.Image(url=gif_filepath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Nombre de jours par régime sur la saison choisie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nc1s=list(cluster[idx_date1:idx_date2]).count(0)\n",
    "nc2s=list(cluster[idx_date1:idx_date2]).count(1)\n",
    "nc3s=list(cluster[idx_date1:idx_date2]).count(2)\n",
    "nc4s=list(cluster[idx_date1:idx_date2]).count(3)\n",
    "\n",
    "f1s=int(nc1s/cluster[idx_date1:idx_date2].shape[0]*100)\n",
    "f2s=int(nc2s/cluster[idx_date1:idx_date2].shape[0]*100)\n",
    "f3s=int(nc3s/cluster[idx_date1:idx_date2].shape[0]*100)\n",
    "f4s=int(nc4s/cluster[idx_date1:idx_date2].shape[0]*100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonction pour la légende."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_regimes_leg(ax):\n",
    "    patch1 = mpatches.Patch(color=couleur[0], label=regime[0]+' : '+str(nc1s)+' ('+str(f1s)+'%)')\n",
    "    patch2 = mpatches.Patch(color=couleur[1], label=regime[1]+' : '+str(nc2s)+' ('+str(f2s)+'%)')\n",
    "    patch3 = mpatches.Patch(color=couleur[2], label=regime[2]+' : '+str(nc3s)+' ('+str(f3s)+'%)')\n",
    "    patch4 = mpatches.Patch(color=couleur[3], label=regime[3]+' : '+str(nc4s)+' ('+str(f4s)+'%)')\n",
    "    all_handles = (patch1, patch2, patch3, patch4)\n",
    "    leg = ax.legend(handles=all_handles, loc='lower right')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bilan des régimes de temps de la saison sous forme de frise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 2))\n",
    "fig.suptitle('Weather regimes : '+date_str_title[0]+' to '+date_str_title[-1], fontsize=14)\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# create a collection with a rectangle for each day\n",
    "col = PatchCollection([Rectangle((y, 0), 1, 1) for y in range(len(pc_dates))])\n",
    "\n",
    "#data = cluster[idx_date1:idx_date2]\n",
    "#col.set_array(data)\n",
    "col.set_color(colors[idx_date1:idx_date2])\n",
    "ax.add_collection(col)\n",
    "\n",
    "if season_name == 'winter':\n",
    "    labels = (\"Dec\", \"Jan\", \"Feb\", \"Mar\")\n",
    "    positions = (0, 31, 31+28, 31+28+31)\n",
    "    if leap_year:\n",
    "        positions = (0, 31, 31+29, 31+29+31)\n",
    "\n",
    "if season_name == 'summer':\n",
    "    positions = (0, 30, 30+31, 30+31+31)\n",
    "    labels = (\"Jun\", \"Jul\", \"Aug\", \"Sep\")\n",
    "\n",
    "plt.xticks(positions, labels)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(0, len(pc_dates))\n",
    "ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "plt.axvline(x=positions[1], c='black')\n",
    "plt.axvline(x=positions[2], c='black')\n",
    "plt.axvline(x=positions[3], c='black')\n",
    "\n",
    "plot_regimes_leg(ax)\n",
    "\n",
    "fig.savefig(dir_figs+varname+'_'+domain_name+'_'+season_name+\n",
    "            '_regimes-stripes_'+date_str_title[0]+'-'+date_str_title[-1]+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Visualisation de la saison considérée dans l'espace des phases défini par PC1 et PC2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.suptitle('PC1 and PC2 phase space : '+date_str_title[0]+' to '+date_str_title[-1], fontsize=14)\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plot_phase_space2d(ax)\n",
    "ax.scatter(pcs[idx_date1:idx_date2,0], pcs[idx_date1:idx_date2,1], c=colors[idx_date1:idx_date2], s=10)\n",
    "ax.scatter(centroids[:, 0], centroids[:, 1], c=couleur, s=2000, alpha=1, marker='+')\n",
    "\n",
    "for i,type in enumerate(date_str):\n",
    "    x = pc1[idx_date1+i]\n",
    "    y = pc2[idx_date1+i]\n",
    "    plt.text(x, y, type, fontsize=6)\n",
    "\n",
    "plot_regimes_leg(ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc12_'+date_str_title[0]+'-'+date_str_title[-1]\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Visualisation de la saison considérée dans l'espace des phases défini par PC1 PC2 et PC3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.suptitle('PC phase space : '+date_str_title[0]+' to '+date_str_title[-1], fontsize=14)\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plot_phase_space3d(ax)\n",
    "ax.scatter(pcs[idx_date1:idx_date2,0], pcs[idx_date1:idx_date2,1], pcs[idx_date1:idx_date2,2],\n",
    "           c=colors[idx_date1:idx_date2], s=10)\n",
    "ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], c=couleur, s=200, alpha=1, marker='+')\n",
    "\n",
    "plot_regimes_leg(ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc123_'+date_str_title[0]+'-'+date_str_title[-1]\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Création des vignettes de la saison considérée dans l'espace des phases défini par PC1 et PC2 (fichiers png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loop for each day\t\n",
    "for i in range(len(pc_dates)):\n",
    " #print(date_str[i])\n",
    " fig = plt.figure(figsize=(10, 10))\n",
    " fig.suptitle('PC1 and PC2 phase space : '+date_str_title[0]+' to '+date_str_title[-1], fontsize=14)\n",
    " ax = fig.add_subplot(1, 1, 1)\n",
    " plot_phase_space2d(ax)\n",
    " ax.scatter(pcs[idx_date1:idx_date1+i+1,0], pcs[idx_date1:idx_date1+i+1,1], \n",
    "            c=colors[idx_date1:idx_date1+i+1], s=10)\n",
    " ax.scatter(centroids[:, 0], centroids[:, 1], c=couleur, s=2000, alpha=1, marker='+')\n",
    " x = pc1[idx_date1+i]\n",
    " y = pc2[idx_date1+i]\n",
    " plt.text(x, y, date_str[i], fontsize=10)\n",
    " plot_regimes_leg(ax)\n",
    " figname=dir_anim+varname+'_'+domain_name+'_'+season_name+'_PC_2d_phase_space_4clusters_'+date_str_title[i]\n",
    " fig.savefig(figname+'.png')\n",
    " plt.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonction de création d'une animation à partir des fichiers png présents dans le dossier anim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_animation2():\n",
    "    nbimages=len(pc_dates)\n",
    "    # create a tuple of display durations, one for each frame\n",
    "    first_last = 1000 #show the first and last frames for 1000 ms\n",
    "    standard_duration = 1000 #show all other frames for 1000 ms\n",
    "    durations = tuple([first_last] + [standard_duration] * (nbimages - 2) + [first_last])\n",
    "    # load all the static images into a list\n",
    "    images = [Image.open(image) for image in sorted(glob.glob('{}/*.png'.format(dir_anim)))]\n",
    "    # save as an animated gif\n",
    "    gif = images[0]\n",
    "    gif.info['duration'] = durations #ms per frame\n",
    "    gif.info['loop'] = 0 #how many times to loop (0=infinite)\n",
    "    gif.save(fp=gif_filepath, format='gif', save_all=True, append_images=images[1:])\n",
    "    # verify that the number of frames in the gif equals the number of image files and durations\n",
    "    Image.open(gif_filepath).n_frames == len(images) == len(durations)\n",
    "    # clean png\n",
    "    os.chdir(dir_anim)\n",
    "    for f in glob.glob(\"*.png\"):\n",
    "        os.remove(f)\n",
    "    os.chdir(\"../\")\n",
    "    return Image"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Animation de la saison considérée dans l'espace des phases défini par PC1 et PC2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gif_filepath = dir_anim+varname+'_'+domain_name+'_'+season_name+'_PC_2d_phase_space_4clusters_'+date_str_title[0]+'-'+date_str_title[-1]+'.gif'\n",
    "make_animation2()\n",
    "IPdisplay.Image(url=gif_filepath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Distances aux centroides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as sdist\n",
    "dist=sdist.cdist(pcs, centroids)\n",
    "dist_c1=dist[:,0]\n",
    "dist_c2=dist[:,1]\n",
    "dist_c3=dist[:,2]\n",
    "dist_c4=dist[:,3]\n",
    "\n",
    "def plot_dist(ax):\n",
    "    plt.ylim(0, 5)\n",
    "    plt.axhline(0, color='k')\n",
    "    plt.xlim(xmin=datetime.datetime(int(str(pc_dates[0])[0:4]), int(str(pc_dates[0])[5:7]),\n",
    "                                    int(str(pc_dates[0])[8:10])),\n",
    "             xmax=datetime.datetime(int(str(pc_dates[-1])[0:4]), int(str(pc_dates[-1])[5:7]),\n",
    "                                    int(str(pc_dates[-1])[8:10])))\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    return ax\n",
    "\n",
    "d1=dist_c1[idx_date1:idx_date2] # distance au régime 1\n",
    "d2=dist_c2[idx_date1:idx_date2] # distance au régime 2\n",
    "d3=dist_c3[idx_date1:idx_date2] # distance au régime 3\n",
    "d4=dist_c4[idx_date1:idx_date2] # distance au régime 4\n",
    "print(d2.shape)\n",
    "\n",
    "fig=plt.figure(figsize=(20, 7))\n",
    "fig.suptitle('Regime distance from centroid', fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(4, 1, 1)\n",
    "plot_dist(ax)\n",
    "plt.scatter(pc_dates, d1, color='blue', s=10000/(d1**6), label='Distance '+regime[0])\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(4, 1, 2)\n",
    "plot_dist(ax)\n",
    "plt.scatter(pc_dates, d2, color='red', s=10000/(d2**6), label='Distance '+regime[1])\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(4, 1, 3)\n",
    "plot_dist(ax)\n",
    "plt.scatter(pc_dates, d3, color='green', s=10000/(d3**6), label='Distance '+regime[2])\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(4, 1, 4)\n",
    "plot_dist(ax)\n",
    "plt.scatter(pc_dates, d4, color='orange', s=10000/(d4**6), label='Distance '+regime[3])\n",
    "plt.axhline(0, color='k')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(dir_figs+varname+'_'+domain_name+'_'+season_name+\n",
    "            '_regimes-distances_'+date_str_title[0]+'-'+date_str_title[-1]+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Séquences record de régime"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster)\n",
    "\n",
    "#with np.printoptions(threshold=np.inf):\n",
    "#    print(cluster)\n",
    "    \n",
    "#for i in range(len(cluster)):\n",
    "#    print(regime[cluster[i]])\n",
    "\n",
    "print(dates2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Top 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "count_dups = [sum(1 for _ in group) for _, group in groupby(cluster)]\n",
    "\n",
    "#print(count_dups)\n",
    "\n",
    "print(\"TOP 20\")\n",
    "for i in range(1,21):\n",
    "    print(\"N°\"+str(i))\n",
    "    print(\"Nombre de jours consécutifs : \", np.sort(count_dups)[-i])\n",
    "    idmax=sum(count_dups[0:np.argsort(count_dups)[-i]]) # indice du maximum d'occurence\n",
    "    print(\"Régime concerné : \", regime[cluster[idmax]])\n",
    "    print(\"Date de début de la séquence : \", dates2[idmax])\n",
    "    print(\"Date de fin de la séquence : \", dates2[idmax+np.sort(count_dups)[-i]-1])\n",
    "    print(\"****************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non prise en compte des régimes non-persistants"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Declustering (no regime si < 3 jours consécutifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non prise en compte des régimes non-persistants"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Corrélation carte du jour / regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Declustering (no regime si corrélation < 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composites avec prise en compte des régimes \"poubelle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartes avec prise en compte des régimes \"poubelle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
